{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49d480",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd38950",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Homework 5<br><br> Time series forecasting </center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "In this homework you will apply time series forecasting methods to the problem of predicting demands for a large power grid. The data comes from [PJM](https://www.pjm.com/about-pjm), a regional transmission organization covering a large portion of the east coast of the United States. Specifically, the data is for northern Illinois. It contains hourly values of electricity demand (in MW) between 2004 and 2010. \n",
    "\n",
    "The homeworks consists of these parts:\n",
    "\n",
    "+ Load the data\n",
    "+ Split the data into training, validation, and testing datasets\n",
    "+ Normalize the data\n",
    "+ Organize the data into input sequences and output values\n",
    "+ Train these models\n",
    "    + Linear regression\n",
    "    + Multi-layer perceptron (a.k.a. dense neural network)\n",
    "    + simple RNN\n",
    "    + LSTM\n",
    "+ Compare the models\n",
    "+ Compute performance of the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad5a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:04.646196Z",
     "iopub.status.busy": "2025-04-22T06:02:04.646024Z",
     "iopub.status.idle": "2025-04-22T06:02:11.080368Z",
     "shell.execute_reply": "2025-04-22T06:02:11.079005Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: If you are running this in JupyterLab, you will have to do the following:\n",
    "# + Run this cell. This will install tensorflow in your JupyterLab environment.\n",
    "# + Comment out the code in this cell, to prevent an unnecessary re-install.\n",
    "# + Restart your kernel (Kernel>Restart kernel...)\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install \"numpy<1.24\"\n",
    "%pip install --upgrade tensorflow==2.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712ca3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:11.084459Z",
     "iopub.status.busy": "2025-04-22T06:02:11.084031Z",
     "iopub.status.idle": "2025-04-22T06:02:13.992269Z",
     "shell.execute_reply": "2025-04-22T06:02:13.991604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.indexes.datetimes import DatetimeIndex\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from hashutils import *\n",
    "os.environ['PYTHONHASHSEED'] = '0'  # optional, for hash-based functions\n",
    "random.seed(2434)\n",
    "np.random.seed(2434)\n",
    "tensorflow.random.set_seed(2434)\n",
    "tensorflow.keras.utils.set_random_seed(2434)\n",
    "tensorflow.config.experimental.enable_op_determinism()\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a56f5",
   "metadata": {},
   "source": [
    "### 0. Load the data into a pandas DataFrame\n",
    "\n",
    "The data is contained in a csv file called `demand.csv`. Load this file into a pandas DataFrame using `read_csv` with the following input arguments:\n",
    "+ index_col=[0]. The first column in the csv file contains the time stamp. This tells pandas to use this as the index of the data frame.\n",
    "+ parse_dates=[0]. This tells pandas to convert the time stamps into DateTime objects.\n",
    "\n",
    "Keep the DataFrame in a variable called `raw_data`.\n",
    "\n",
    "**Note**: This part has already been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a47015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:13.995086Z",
     "iopub.status.busy": "2025-04-22T06:02:13.994698Z",
     "iopub.status.idle": "2025-04-22T06:02:14.049646Z",
     "shell.execute_reply": "2025-04-22T06:02:14.049070Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('demand.csv', index_col=[0], parse_dates=[0])\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec17e5c",
   "metadata": {},
   "source": [
    "### Plot the full time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b593e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.051791Z",
     "iopub.status.busy": "2025-04-22T06:02:14.051558Z",
     "iopub.status.idle": "2025-04-22T06:02:14.308619Z",
     "shell.execute_reply": "2025-04-22T06:02:14.308218Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf117c2",
   "metadata": {},
   "source": [
    "### 1. Split the data into training, validation, and testing datasets\n",
    "\n",
    "Write a function called `split_data` that takes these arguments:\n",
    "+ `pt`: A number between 0 and 1 corresponding to the proportion of the data to be used for *training*.\n",
    "+ `pv`: A number between 0 and 1 corresponding to the proportion of the data to be used for *validation*. Validation here means that it will be used by the fitting function of the neural network to evaluate the model at each step of stochastic gradient descent. \n",
    "\n",
    "The function should return 3 pandas DataFrames: `data_train`, `data_validate`, and `data_test` (in that order). \n",
    "\n",
    "Each of these should contain a **copy** of the segment of `raw_data` that will be used for training, validation, and testing respectively. \n",
    "\n",
    "The length of `data_train` should be the integer part of `N*pt`, where `N` is the total number of samples in `raw_data`. Similarly for `data_validate`.\n",
    "\n",
    "**Notes**:\n",
    "+ `raw_data` is not passed to `split_data` because it is a global variable.\n",
    "+ Training data should precede validation data in time. \n",
    "+ Validation data should precede testing data in time.\n",
    "\n",
    "**Hint**:\n",
    "+ [DataFrame.copy](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0acff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.310539Z",
     "iopub.status.busy": "2025-04-22T06:02:14.310347Z",
     "iopub.status.idle": "2025-04-22T06:02:14.315239Z",
     "shell.execute_reply": "2025-04-22T06:02:14.314866Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def split_data(pt,pv):\n",
    "\n",
    "    assert(pt>=0)\n",
    "    assert(pv>=0)\n",
    "    assert(pt+pv<=1)\n",
    "\n",
    "    ...\n",
    "    \n",
    "    return data_train, data_validate, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb2931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.317003Z",
     "iopub.status.busy": "2025-04-22T06:02:14.316678Z",
     "iopub.status.idle": "2025-04-22T06:02:14.319087Z",
     "shell.execute_reply": "2025-04-22T06:02:14.318609Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# test your code:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344da57",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc019b",
   "metadata": {},
   "source": [
    "### 2. Split the data\n",
    "\n",
    "Use your `split_data` function to split the data with the following proportions:\n",
    "+ `data_train`, with %70 of the data,\n",
    "+ `data_validate`, with %10 of the data,\n",
    "+ `data_test`, with %20 of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a2029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.351142Z",
     "iopub.status.busy": "2025-04-22T06:02:14.350947Z",
     "iopub.status.idle": "2025-04-22T06:02:14.355495Z",
     "shell.execute_reply": "2025-04-22T06:02:14.355033Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data_train, data_validate, data_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5933a1f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068f233",
   "metadata": {},
   "source": [
    "### Plot the training, validation, and test data.\n",
    "\n",
    "Done already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d85022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.369872Z",
     "iopub.status.busy": "2025-04-22T06:02:14.369620Z",
     "iopub.status.idle": "2025-04-22T06:02:14.808805Z",
     "shell.execute_reply": "2025-04-22T06:02:14.808206Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data_train,label='training data')\n",
    "plt.plot(data_validate,label='validation data')\n",
    "plt.plot(data_test,label='test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662733fb",
   "metadata": {},
   "source": [
    "### 3. Normalize the data\n",
    "\n",
    "Use ScikitLearn's `StandardScaler` to normalize the data. Normalizing a dataset, as we've seen, means subtracting its mean and dividing by its standard deviation. This can improve the performance of certain \"scale-dependent\" models, such as neural networks. (decision trees are scale-*independent*)\n",
    "\n",
    "Follow these steps:\n",
    "1. Create a `StandardScaler` object. You can name it whatever you like (e.g. \"scaler\").\n",
    "2. Pass the training data (`data_train`) to its `fit` method. This will compute and store the mean and standard deviation of the training sequence. \n",
    "3. Apply the scaling transformation to the training sequence by passing it to the scaler's `transform` method. Save the result in a column called `\"scaled\"` in the training data DataFrame (`data_train`). \n",
    "4. Do the same for `data_validate` and `data_test`.\n",
    "\n",
    "After doing this, `data_train` should look like this:\n",
    "\n",
    "<img src=\"df.png\" width=350 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37498c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.811037Z",
     "iopub.status.busy": "2025-04-22T06:02:14.810839Z",
     "iopub.status.idle": "2025-04-22T06:02:14.829000Z",
     "shell.execute_reply": "2025-04-22T06:02:14.828437Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6646de4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf17d49",
   "metadata": {},
   "source": [
    "### Plot the scaled training, validation, and test data. \n",
    "\n",
    "Done already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb07ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:14.859639Z",
     "iopub.status.busy": "2025-04-22T06:02:14.859409Z",
     "iopub.status.idle": "2025-04-22T06:02:15.279094Z",
     "shell.execute_reply": "2025-04-22T06:02:15.278497Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data_train['scaled'],label='scaled training data')\n",
    "plt.plot(data_validate['scaled'],label='scaled validation data')\n",
    "plt.plot(data_test['scaled'],label='scaled test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fff390",
   "metadata": {},
   "source": [
    "### 4. Organize the data into input and output sequences\n",
    "\n",
    "Our goal is to build a model that can forecast the power demand $F$ hours in the future using the $T$ most recent hourly values. To train this model we must organize the training sequence into an input matrix $\\mathbf{X}$ and output column vector $\\mathbf{Y}$. With $N$ denoting the length of the training sequence (in our case $N=40,915$, as you can verify), the number of rows in $\\mathbf{X}$ will be \n",
    "$$N' = N-F-T+1$$\n",
    "The number of columns in $\\mathbf{X}$ is $T$.\n",
    "\n",
    "Write a function called `organize_data` that takes these arguments:\n",
    "+ `d`: a pandas Series object such as `data_train['scaled']`. \n",
    "+ `T`: $T$ as described above.\n",
    "+ `F`: $F$ as described above.\n",
    "\n",
    "The function should return the following:\n",
    "+ `X`, a 2D NumPy array with $N'$ rows and $T$ columns containing the matrix $\\mathbf{X}$.\n",
    "+ `Y`, a 1D NumPy array with $N'$ entries containing the vector $\\mathbf{Y}$.\n",
    "+ `t`, a 1D NumPy array with timestamps for each sample. Each timestamp is a `DatetimeIndex` object.\n",
    "\n",
    "The two figures below illustrate the organization of $\\mathbf{t}$, $\\mathbf{X}$, and $\\mathbf{Y}$. The first figure shows three input/output samples (green, orange, and blue). The inputs are the sequences of length $T=14$. For example, the green input sequence is collected at 5:00 PM, and it consists of hourly data starting at 4:00 AM. The output of the model is trained to match the forecasted green point at 8:00 PM. \n",
    "\n",
    "Similarly, the orange sample consists of an input sequence, collected at 6:00 PM and consisting of  14 hourly values from 5:00 AM to 6:00 PM, and used to predict a value at 9:00 PM.\n",
    "\n",
    "<img src=\"samples.png\" width=800 />\n",
    "\n",
    "\n",
    "These samples are arranged into arrays $\\mathbf{t}$, $\\mathbf{X}$, and $\\mathbf{Y}$ as shown below. Notice that the timestamp $\\mathbf{t}$ corresponds to the time at which the prediction is made, which is also the time at which the left-most column of $\\mathbf{X}$ is measured. For example, the time stamp for the green sample is 5:00 PM.\n",
    "\n",
    "\n",
    "<img src=\"snipets.png\" width=700 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb016aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:15.281374Z",
     "iopub.status.busy": "2025-04-22T06:02:15.281187Z",
     "iopub.status.idle": "2025-04-22T06:02:15.285770Z",
     "shell.execute_reply": "2025-04-22T06:02:15.285272Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def organize_data(d,F,T):\n",
    "\n",
    "    N = d.shape[0]\n",
    "    Np = N - F - T + 1\n",
    "    X = np.empty((Np,T))\n",
    "    Y = np.empty(Np)\n",
    "    t = np.empty(Np,dtype=DatetimeIndex)\n",
    "\n",
    "    # Fill in X, Y, and t\n",
    "    ...\n",
    "\n",
    "    return X, Y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e2604",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b14498",
   "metadata": {},
   "source": [
    "### 5. Call `organize_data` on the training, validation, and test data\n",
    "\n",
    "We wish to predict the power demand $F=12$ hours in the future from the $T=6$ most recent values. Use `organize_data` to assemble $\\mathbf{X}$ and $\\mathbf{Y}$ arrays for the **scaled** training, validation, and test data. \n",
    "\n",
    "Call these:\n",
    "+ `Xtrain` and `ytrain` for the training data.\n",
    "+ `Xvalid` and `yvalid` for the validation data.\n",
    "+ `Xtest` and `ytest` for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd4ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:15.309523Z",
     "iopub.status.busy": "2025-04-22T06:02:15.309275Z",
     "iopub.status.idle": "2025-04-22T06:02:17.660588Z",
     "shell.execute_reply": "2025-04-22T06:02:17.660031Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "T = ...\n",
    "F = ...\n",
    "Xtrain, ytrain, ttrain = ...\n",
    "Xvalid, yvalid, tvalid = ...\n",
    "Xtest, ytest, ttest = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9ef80",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c698c38",
   "metadata": {},
   "source": [
    "### Plot the individual sequences\n",
    "\n",
    "The plot below shows a few sequences in `Xtrain`, jiggled by a small amount so that they do not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692a049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.716552Z",
     "iopub.status.busy": "2025-04-22T06:02:17.716359Z",
     "iopub.status.idle": "2025-04-22T06:02:17.850506Z",
     "shell.execute_reply": "2025-04-22T06:02:17.850077Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,3))\n",
    "for i in range(50):\n",
    "    ax.plot(range(i,i+T),Xtrain[i,:]+np.random.normal(scale=0.02),marker='.',linewidth=1)\n",
    "ax.spines[['top','right','bottom']].set_visible(False)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d5b2c",
   "metadata": {},
   "source": [
    "### 6. Linear regression\n",
    "\n",
    "Train a Scikit-learn linear regression model using `Xtrain` and `ytrain`. \n",
    "+ Do not pass any arguments to the `LinearRegression` constructor. \n",
    "+ Save the trained model in the variable `linreg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ffead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.852570Z",
     "iopub.status.busy": "2025-04-22T06:02:17.852376Z",
     "iopub.status.idle": "2025-04-22T06:02:17.909156Z",
     "shell.execute_reply": "2025-04-22T06:02:17.908571Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a8469",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e9dd1",
   "metadata": {},
   "source": [
    "### 7. Performance relative to a baseline model\n",
    "\n",
    "Let's decide on a performance metric to use. \n",
    "\n",
    "Consider the coefficient of determination, $R^2$: \n",
    "$$ R^2 = 1 - \\frac{\\sum(\\hat{y}_i-y_i)^2}{\\sum(\\hat{y}_i-\\bar{y})^2}$$\n",
    "This metric compares the MSE of a model to that of a \"baseline\" prediction $\\bar{y}$, which is simply the mean of the training outputs $\\{y_i\\}_N$. This makes sense for iid data, but it is too simplistic for time series data. A better baseline for the forecasting problem is to predict that *the future is the same as the present*. In other words, we predict that the value of the power demand in $F$ hours will be the same as the current value. This is illustrated in the figure below for $T=3$ and $F=6$.\n",
    "\n",
    "<img src=\"baseline.png\" width=700 /> \n",
    "\n",
    "The mean absolute error of the model is given by,\n",
    "\n",
    "$$\\text{MAE(model)} = \\frac{1}{N'} \\sum_{k} \\left( |x_{k+F}-\\hat{y}_k| \\right)    $$\n",
    "\n",
    "The baseline mean absolute error of the model is,\n",
    "\n",
    "$$\\text{MAE(baseline)} = \\frac{1}{N'} \\sum_{k} \\left( |x_{k+F}-x_k| \\right)    $$\n",
    "\n",
    "\n",
    "The performance of the model is then obtained, analogously to $R^2$ by comparing the MAE of the model to the baseline MAE:\n",
    "\n",
    "$$ \\text{Performance(model)} = 1 - \\frac{\\text{MAE(model)}}{\\text{MAE(baseline)}}$$\n",
    "\n",
    "Note that the baseline performance is 0, while a \"perfect\" model (with zero MAE) would have a performance of 1. Better models have larger values of performance.\n",
    "\n",
    "Write a function called `assess` that implements this performance metric. The function should take these input arguments:\n",
    "+ `x_current`: a NumPy array with the *current* values of power demand ($x_k$ above). \n",
    "+ `y`: a NumPy array with the true future values of power demand ($y_k$ above). \n",
    "+ `yhat`: a NumPy array with the model predictions ($\\hat{y}_k$ above). \n",
    "\n",
    "**Hint**\n",
    "+ To compute the performance of the linear regression model on the validation data we would run\n",
    "\n",
    "```python \n",
    "assess( x_current = Xtrain[:,-1],\n",
    "        y = ytrain,\n",
    "        yhat = linreg.predict(Xtrain))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f489980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.931913Z",
     "iopub.status.busy": "2025-04-22T06:02:17.931628Z",
     "iopub.status.idle": "2025-04-22T06:02:17.935329Z",
     "shell.execute_reply": "2025-04-22T06:02:17.934967Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def assess(x_current,y,yhat):\n",
    "    ...\n",
    "    perf = ...\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba79cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.936756Z",
     "iopub.status.busy": "2025-04-22T06:02:17.936546Z",
     "iopub.status.idle": "2025-04-22T06:02:17.942737Z",
     "shell.execute_reply": "2025-04-22T06:02:17.942293Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'Performance of linear regression on the training data: {assess(Xtrain[:,-1],ytrain,linreg.predict(Xtrain)):.4f}')\n",
    "print(f'Performance of linear regression on the validation data: {assess(Xvalid[:,-1],yvalid,linreg.predict(Xvalid)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb6f06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ae968",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 8. Include hour-of-day\n",
    "\n",
    "Our linear regression model is performing only about 30\\% closer to \"perfect prediction\" than the baseline model. Let's see if we can improve it.\n",
    "\n",
    " We know that demand for electricity is more or less periodic over a day. Hence, hour-of-day may be a useful input to include in the model. To test this idea, we must first write a function that appends the hour-of-day as a final (right-most) column in our input matrix $\\mathbf{X}$. \n",
    "\n",
    "Write a function called `append_hour_of_day` that takes these input arguments: \n",
    "+ `X`: A 2D NumPy array of input sequences, such as `Xtrain`, `Xvalid`, or `Xtest`.\n",
    "+ `t`: A 1D NumPy array of time stamps, such as `ttrain`, `tvalid`, or `ttest`.\n",
    "\n",
    "The function should return a new 2D NumPy array with `X` as its first $T$ columns, and the *hour-of-the-day* in its last column.  The hour-of-the-day is an integer between 0 and 23 inclusive. It is stored as the `hour` attribute of each element in `t`, e.g. `ttrain[0].hour`.\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "+ Running `append_hour_of_day(Xtrain,ttrain)` should return an array whose first 5 rows are:\n",
    "\n",
    "<img src=\"xtrainhour.png\" width=600 /> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5c18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.963226Z",
     "iopub.status.busy": "2025-04-22T06:02:17.963048Z",
     "iopub.status.idle": "2025-04-22T06:02:17.966337Z",
     "shell.execute_reply": "2025-04-22T06:02:17.966007Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def append_hour_of_day(X,t):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45f6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.967675Z",
     "iopub.status.busy": "2025-04-22T06:02:17.967447Z",
     "iopub.status.idle": "2025-04-22T06:02:17.974811Z",
     "shell.execute_reply": "2025-04-22T06:02:17.974431Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# test your code\n",
    "Xtrain_hour = append_hour_of_day(Xtrain,ttrain)\n",
    "Xtrain_hour[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1dd62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e08480",
   "metadata": {},
   "source": [
    "### 9. Include hour-of-day in training, validation, and test data\n",
    "\n",
    "Run your `append_hour_of_day` on the training, validation, and test data. Store the results as \n",
    "`Xtrain_hour`, `Xvalid_hour`, and `Xtest_hour` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65522fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:17.992608Z",
     "iopub.status.busy": "2025-04-22T06:02:17.992444Z",
     "iopub.status.idle": "2025-04-22T06:02:18.001681Z",
     "shell.execute_reply": "2025-04-22T06:02:18.001184Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60906077",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133e484",
   "metadata": {},
   "source": [
    "### 10. New linear regression with hour-of-day\n",
    "\n",
    "Train a new linear regression model using the input matrix that includes hour-of-day. Save the fitted model as `linreg_hour`.\n",
    "\n",
    "Compute the performance of both linear regression models on the validation data. Save the performance of `linreg` to `linreg_perf`, and of `linreg_hour` to `linreg_hour_perf`. Did the performance improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdb581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:18.028087Z",
     "iopub.status.busy": "2025-04-22T06:02:18.027897Z",
     "iopub.status.idle": "2025-04-22T06:02:18.039231Z",
     "shell.execute_reply": "2025-04-22T06:02:18.038835Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2555063",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e830a3",
   "metadata": {},
   "source": [
    "### 11. Build an MLP \n",
    "\n",
    "We will now try several neural network models to see whether they can deliver better performance than linear regression. We begin with a multi-layer perceptron (MLP).\n",
    "\n",
    "Build a MLP model for the forecast problem with the hour-of-the-day as an additional input. The model should have this sequence of layers:\n",
    "1. A dense layer with 64 units and ReLU activation.\n",
    "2. A dense layer with 32 units and ReLU activation.\n",
    "3. A dense layer with 16 units and ReLU activation.\n",
    "4. A dense layer with 1 units no activation (this is the output layer).\n",
    "\n",
    "Each layer should also be passed a `kernel_initalizer`, which is set to a `GlorotUniform` object. This is done for you in this part, but you should add it to neural networks in parts 13 and 14 as well. This is needed to guarantee repeatability of the results. \n",
    "\n",
    "Use variable name `model_mlp` for this model.\n",
    "\n",
    "Compile the model with its `compile` method and these input arguments:\n",
    "+ `optimizer=\"rmsprop\"`. Tells Keras to use the \"root-mean-squared propagation\" variant of stochastic gradient descent for training. \n",
    "+ `loss=\"mse\"`: Use the L2 loss function. \n",
    "+ `metrics=[\"mae\"]`: Record the mean absolute error at the end of each epoch.\n",
    "\n",
    "**Note**\n",
    "+ You will have to pass the `input_shape` to the first layer of the MLP. This should be set to `input_shape=(D,)`, where `D` is the number of features in your training data (i.e. in `Xtrain_hour`) \n",
    "+ We also have to pass a \"kernel initializer\" to each of the layers. This determines the manner in which the weights on each of the edges of the neural network are initialized. We use a random seed to ensure that the initialization is the same every time, so that the autograder can work correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ce503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:18.058580Z",
     "iopub.status.busy": "2025-04-22T06:02:18.058403Z",
     "iopub.status.idle": "2025-04-22T06:02:18.156028Z",
     "shell.execute_reply": "2025-04-22T06:02:18.155593Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "\n",
    "ki = GlorotUniform(seed=2434) # This is needed for reproducibility of the results\n",
    "\n",
    "model_mlp = Sequential([\n",
    "    Dense(..., input_shape=..., activation=..., kernel_initializer=ki),\n",
    "    Dense(..., activation=..., kernel_initializer=ki),\n",
    "    Dense(..., activation=..., kernel_initializer=ki),\n",
    "    Dense(..., kernel_initializer=ki)\n",
    "])\n",
    "\n",
    "model_mlp.compile( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89508b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5960a1",
   "metadata": {},
   "source": [
    "### 12. Train the MLP\n",
    "\n",
    "Train your MLP by calling its `fit` function. Use these input arguments:\n",
    "+ `x=Xtrain_hour`. Use the training data matrix that includes the hour-of-the-day.\n",
    "+ `y=ytrain`. Training target.\n",
    "+ `epochs=10`. Train for 10 epochs.\n",
    "+ `validation_data=(Xvalid_hour,yvalid)`. Pass in the validation data so that Keras can track the MAE of the model.\n",
    "\n",
    "Save the output of the fit function to the variable name `history_mlp`.\n",
    "\n",
    "Use the `assess` function to evaluate the performance of your trained model using the validation data.\n",
    "\n",
    "**Note**\n",
    "+ We must copy the code from the previous part into this cell, so that the neural network is created and compiled afresh each time before training. This is to ensure reproducibility of the results and proper function of the autograder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60539c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:18.240729Z",
     "iopub.status.busy": "2025-04-22T06:02:18.240543Z",
     "iopub.status.idle": "2025-04-22T06:02:53.813497Z",
     "shell.execute_reply": "2025-04-22T06:02:53.813055Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(2434)  # Do not change this. It is needed to ensure repeatability.\n",
    "\n",
    "\n",
    "### Copy your code from the previous part here ####\n",
    "\n",
    "###################################################\n",
    "\n",
    "history_mlp = model_mlp.fit(...)\n",
    "\n",
    "print('Validation: ',assess(Xvalid[:,-1],yvalid,model_mlp.predict(Xvalid_hour)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f84604",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657b08d",
   "metadata": {},
   "source": [
    "### Plot the training history for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0fd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:53.829611Z",
     "iopub.status.busy": "2025-04-22T06:02:53.829343Z",
     "iopub.status.idle": "2025-04-22T06:02:53.947791Z",
     "shell.execute_reply": "2025-04-22T06:02:53.947288Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = len(history_mlp.epoch)\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(range(num_epochs), history_mlp.history[\"mae\"],marker='o', label=\"Training MAE\")\n",
    "plt.plot(range(num_epochs), history_mlp.history[\"val_mae\"],marker='o', label=\"Validation MAE\")\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Training of MLP\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062ae85",
   "metadata": {},
   "source": [
    "### 13. Build and train a SimpleRNN\n",
    "\n",
    "Next, create a neural network with simple RNN units. The model should have this sequence of layers:\n",
    "1. A SimpleRNN layer with **32** units. Because this is the first layer of the neural netork, we must define the shape of the input. Set `input_shape=(D,1)`. Also, with recurrent layers that feed into downstream recurrent layers, we need to pass `return_sequences=True`.\n",
    "2. A SimpleRNN layer with **32** units. Again pass `return_sequences=True`.\n",
    "2. A SimpleRNN layer with **16** units. No need to pass `return_sequences=True` in this case because the next downstream layer is dense.\n",
    "3. A dense layer with **1** unit and no activation (this is the output layer).\n",
    "\n",
    "**Notes**:\n",
    "+ Use variable name `model_srnn` for this model.\n",
    "+ Do not pass an `activation` to any of the SimpleRNN layers.\n",
    "+ Compile the model with its `compile` method and the same input arguments as in part 11.\n",
    "+ Train your simple RNN model by calling its `fit` function. Use the same input arguments as in part 12.\n",
    "+ Save the output of the fit function to the variable name `history_srnn`.\n",
    "+ Use the `assess` function to evaluate the performance of your trained model using the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c346ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:02:53.950111Z",
     "iopub.status.busy": "2025-04-22T06:02:53.949889Z",
     "iopub.status.idle": "2025-04-22T06:03:53.278442Z",
     "shell.execute_reply": "2025-04-22T06:03:53.277954Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "random.seed(2434)  # Do not change this. It is needed to ensure repeatability.\n",
    "\n",
    "model_srnn = ...\n",
    "\n",
    "print('Validation: ',assess(Xvalid[:,-1],yvalid,model_srnn.predict(Xvalid_hour)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447417e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f4f52",
   "metadata": {},
   "source": [
    "### Plot the training history of the Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804cc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:03:53.365592Z",
     "iopub.status.busy": "2025-04-22T06:03:53.365450Z",
     "iopub.status.idle": "2025-04-22T06:03:53.488118Z",
     "shell.execute_reply": "2025-04-22T06:03:53.487538Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = len(history_srnn.epoch)\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(range(num_epochs), history_srnn.history[\"mae\"],marker='o', label=\"Training MAE\")\n",
    "plt.plot(range(num_epochs), history_srnn.history[\"val_mae\"],marker='o', label=\"Validation MAE\")\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Training of Simple RNN\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4494de",
   "metadata": {},
   "source": [
    "### 14. Build and train an LSTM \n",
    "\n",
    "Finally, create a neural network with LSTM units. The instructions are identical to those of the simple RNN.\n",
    "\n",
    "The model should have this sequence of layers:\n",
    "1. A LSTM layer with **16** units. Because this is the first layer of the neural netork, we must define the shape of the input. Set `input_shape=(D,1)`. Also, with recurrent layers that feed into downstream recurrent layers, we need to pass `return_sequences=True`.\n",
    "2. A LSTM layer with **16** units. Again pass `return_sequences=True`.\n",
    "2. A LSTM layer with **8** units. No need to pass pass `return_sequences=True` in this case because the next downstream layer is dense.\n",
    "3. A dense layer with **1** unit and no activation (this is the output layer).\n",
    "\n",
    "**Notes**:\n",
    "+ Use variable name `model_lstm` for this model.\n",
    "+ Do not pass an `activation` to any of the LSTM layers.\n",
    "+ Compile the model with its `compile` method and the same input arguments as in part 11.\n",
    "+ Train your LSTM model by calling its `fit` function. Use the same input arguments as in part 12.\n",
    "+ Save the output of the fit function to the variable name `history_lstm`.\n",
    "+ Use the `assess` function to evaluate the performance of your trained model using the validation data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d9fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:03:53.490396Z",
     "iopub.status.busy": "2025-04-22T06:03:53.490214Z",
     "iopub.status.idle": "2025-04-22T06:05:28.984419Z",
     "shell.execute_reply": "2025-04-22T06:05:28.983729Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "random.seed(2434)  # Do not change this. It is needed to ensure repeatability.\n",
    "\n",
    "model_lstm = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355a3d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a2872",
   "metadata": {},
   "source": [
    "### Plot the training history of the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf1e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:05:29.145494Z",
     "iopub.status.busy": "2025-04-22T06:05:29.145162Z",
     "iopub.status.idle": "2025-04-22T06:05:29.272123Z",
     "shell.execute_reply": "2025-04-22T06:05:29.271575Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = len(history_lstm.epoch)\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(range(num_epochs), history_lstm.history[\"mae\"],marker='o', label=\"Training MAE\")\n",
    "plt.plot(range(num_epochs), history_lstm.history[\"val_mae\"],marker='o', label=\"Validation MAE\")\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Training of LSTM\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a353ec",
   "metadata": {},
   "source": [
    "### Single plot with the training histories of our three neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8544c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:05:29.274297Z",
     "iopub.status.busy": "2025-04-22T06:05:29.273877Z",
     "iopub.status.idle": "2025-04-22T06:05:29.395405Z",
     "shell.execute_reply": "2025-04-22T06:05:29.394969Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = len(history_lstm.epoch)\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(range(num_epochs), history_mlp.history[\"val_mae\"], '.-',markersize=10,label=\"MLP validation MAE\")\n",
    "plt.plot(range(num_epochs), history_srnn.history[\"val_mae\"], '.-',markersize=10,label=\"sRNN validation MAE\")\n",
    "plt.plot(range(num_epochs), history_lstm.history[\"val_mae\"], '.-',markersize=10, label=\"LSTM validation MAE\")\n",
    "plt.title(\"Validation MAE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400f4a6",
   "metadata": {},
   "source": [
    "### 15. Pick the best model\n",
    "\n",
    "Evaluate the performance of the four models (linear regression with hour-of-day, MLP, simple RNN, and LSTM) using the validation data (again). Store the result in these variable names: \n",
    "+ `linreg_hour_perf`\n",
    "+ `mlp_perf`\n",
    "+ `srnn_perf`\n",
    "+ `lstm_perf`\n",
    "\n",
    "Choose the best one and save it as `best_model`. For example, if the linear regression model were the best one, your would write:\n",
    "```python \n",
    "best_model = linreg_hour\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbbe39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:05:29.397490Z",
     "iopub.status.busy": "2025-04-22T06:05:29.397307Z",
     "iopub.status.idle": "2025-04-22T06:05:31.435837Z",
     "shell.execute_reply": "2025-04-22T06:05:31.435410Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af71d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49debd15",
   "metadata": {},
   "source": [
    "### 16. Final model test performance\n",
    "\n",
    "Now that we have made a final selection of a model, it is time to use the test dataset. \n",
    "\n",
    "Evaluate the performance of `best_model` on the test data. Save the result to the variable `best_perf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddd9c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:05:31.457736Z",
     "iopub.status.busy": "2025-04-22T06:05:31.457455Z",
     "iopub.status.idle": "2025-04-22T06:05:32.044013Z",
     "shell.execute_reply": "2025-04-22T06:05:32.043593Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ed35a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25672f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ea9ec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bdcbe",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw5",
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> dtrain, dval, dtest = split_data(pt=0.5, pv=0.3)\n>>> type(dtrain) == pd.core.frame.DataFrame and type(dval) == pd.core.frame.DataFrame and (type(dtest) == pd.core.frame.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dtrain, dval, dtest = split_data(pt=0.5, pv=0.3)\n>>> dtrain.shape == (29225, 1) and dval.shape == (17535, 1) and (dtest.shape == (11690, 1))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dtrain, dval, dtest = split_data(pt=0.5, pv=0.3)\n>>> dtrain.index.max() < dval.index.min() and dval.index.max() < dtest.index.min()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dtrain, dval, dtest = split_data(pt=0.7, pv=0.1)\n>>> dtrain.iloc[0, 0] = 0\n>>> bool(raw_data.iloc[0, 0] == 9198.0)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dtrain, dval, dtest = split_data(pt=0.7, pv=0.1)\n>>> dtrain.index.is_monotonic_increasing and dval.index.is_monotonic_increasing and dtest.index.is_monotonic_increasing\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(linreg_hour, LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> hasattr(linreg_hour, 'coef_') and hasattr(linreg_hour, 'intercept_')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(linreg_hour.coef_, 4) == '041f305f9a93af48e041d3ff6cf628a8' and get_hash(linreg_hour.intercept_, 4) == '05d4938f03ae6ca2613a71cf2cf09bc7'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(linreg_perf, 4) == 'ff5bb1d297b5bd5a242bf2af6a328b0e' and get_hash(linreg_hour_perf, 4) == 'c982c2eafe1b27be578ba76bdd4b1464'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l0 = model_mlp.get_config()['layers'][0]\n>>> l0['class_name'] == 'InputLayer'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l0 = model_mlp.get_config()['layers'][0]['config']\n>>> l0['batch_shape'] == (None, 7)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_mlp.get_config()['layers'][1]\n>>> l1['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_mlp.get_config()['layers'][1]['config']\n>>> l1['units'] == 64 and l1['activation'] == 'relu'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_mlp.get_config()['layers'][2]\n>>> l2['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_mlp.get_config()['layers'][2]['config']\n>>> l2['units'] == 32 and l2['activation'] == 'relu'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_mlp.get_config()['layers'][3]\n>>> l3['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_mlp.get_config()['layers'][3]['config']\n>>> l3['units'] == 16 and l3['activation'] == 'relu'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_mlp.get_config()['layers'][4]\n>>> l4['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_mlp.get_config()['layers'][4]['config']\n>>> l4['units'] == 1 and l4['activation'] == 'linear'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_mlp.get_compile_config()\n>>> 'optimizer' in cfg.keys() and cfg['optimizer']['class_name'] == 'RMSprop'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_mlp.get_compile_config()\n>>> 'loss' in cfg.keys() and cfg['loss'] == 'mse'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_mlp.get_compile_config()\n>>> 'metrics' in cfg.keys() and len(cfg['metrics']) == 1 and (cfg['metrics'][0] == 'mae')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12": {
     "name": "q12",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(history_mlp.epoch) == 10\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(history_mlp.history['mae'], 4) == '180dd7609acd3f40312247e7551658d2'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(history_mlp.history['val_mae'], 4) == 'a57e2fa3558b8f9e04e7f01b4fc7abc9'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q13": {
     "name": "q13",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l0 = model_srnn.get_config()['layers'][0]\n>>> l0['class_name'] == 'InputLayer'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l0 = model_srnn.get_config()['layers'][0]['config']\n>>> l0['batch_shape'] == (None, 7, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_srnn.get_config()['layers'][1]\n>>> l1['class_name'] == 'SimpleRNN'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_srnn.get_config()['layers'][1]['config']\n>>> l1['units'] == 32\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_srnn.get_config()['layers'][2]\n>>> l2['class_name'] == 'SimpleRNN'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_srnn.get_config()['layers'][2]['config']\n>>> l2['units'] == 32\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_srnn.get_config()['layers'][3]\n>>> l3['class_name'] == 'SimpleRNN'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_srnn.get_config()['layers'][3]['config']\n>>> l3['units'] == 16\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_srnn.get_config()['layers'][4]\n>>> l4['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_srnn.get_config()['layers'][4]['config']\n>>> l4['units'] == 1 and l4['activation'] == 'linear'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_srnn.get_compile_config()\n>>> 'optimizer' in cfg.keys() and cfg['optimizer']['class_name'] == 'RMSprop'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_srnn.get_compile_config()\n>>> 'loss' in cfg.keys() and cfg['loss'] == 'mse'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_srnn.get_compile_config()\n>>> 'metrics' in cfg.keys() and len(cfg['metrics']) == 1 and (cfg['metrics'][0] == 'mae')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> len(history_srnn.epoch) == 10\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(history_srnn.history['mae'], 4) == 'f5116737e7ed6d38fa5196c037ccdb8f'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(history_srnn.history['val_mae'], 4) == '4977e75a76d79d0a4d099568c2a36a6a'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q14": {
     "name": "q14",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l0 = model_lstm.get_config()['layers'][0]\n>>> l0['class_name'] == 'InputLayer'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l0 = model_lstm.get_config()['layers'][0]['config']\n>>> l0['batch_shape'] == (None, 7, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_lstm.get_config()['layers'][1]\n>>> l1['class_name'] == 'LSTM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l1 = model_lstm.get_config()['layers'][1]['config']\n>>> l1['units'] == 16\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_lstm.get_config()['layers'][2]\n>>> l2['class_name'] == 'LSTM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l2 = model_lstm.get_config()['layers'][2]['config']\n>>> l2['units'] == 16\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_lstm.get_config()['layers'][3]\n>>> l3['class_name'] == 'LSTM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l3 = model_lstm.get_config()['layers'][3]['config']\n>>> l3['units'] == 8\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_lstm.get_config()['layers'][4]\n>>> l4['class_name'] == 'Dense'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> l4 = model_lstm.get_config()['layers'][4]['config']\n>>> l4['units'] == 1 and l4['activation'] == 'linear'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_lstm.get_compile_config()\n>>> 'optimizer' in cfg.keys() and cfg['optimizer']['class_name'] == 'RMSprop'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_lstm.get_compile_config()\n>>> 'loss' in cfg.keys() and cfg['loss'] == 'mse'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> cfg = model_lstm.get_compile_config()\n>>> 'metrics' in cfg.keys() and len(cfg['metrics']) == 1 and (cfg['metrics'][0] == 'mae')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> len(history_lstm.epoch) == 10\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(history_lstm.history['mae'], 4) == '8848ccee3942fc58ef6acce8cb93f955'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(history_lstm.history['val_mae'], 4) == 'd3d9516b9e778bc3a47c45e19524250c'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q15": {
     "name": "q15",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(mlp_perf, 0.6643458510404325, atol=0.0001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(linreg_hour_perf, 4) == 'c982c2eafe1b27be578ba76bdd4b1464'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(mlp_perf, 4) == '4893e3f17711364b417e77032bc5b1e4' and get_hash(srnn_perf, 4) == '609d69aa26e276cc06ec8b834cc73ab5' and (get_hash(lstm_perf, 4) == '8a52647f06947d3d26632ec454dd25d7')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(best_model.get_config()['layers'][1]['class_name']) == '9a71a13863c84ba34fc41595fc2ee0c6'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q16": {
     "name": "q16",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_perf > 0.6 and best_perf < 0.7\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(best_perf, 4) == '3fb54c972c18f517326eae8b12ca275a'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data_train.shape == (40915, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> data_validate.shape == (5845, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> data_test.shape == (11690, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(data_train.columns) == {'power demand [MW]', 'scaled'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> set(data_validate.columns) == {'power demand [MW]', 'scaled'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> set(data_test.columns) == {'power demand [MW]', 'scaled'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.isclose(data_train['scaled'].values.mean(), 0.0) and np.isclose(data_train['scaled'].values.std(), 1.0))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.isclose(data_validate['scaled'].values.mean(), -0.173909) and np.isclose(data_validate['scaled'].values.std(), 0.899079))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.isclose(data_test['scaled'].values.mean(), -0.07913193) and np.isclose(data_test['scaled'].values.std(), 0.98475571087))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> xa, ya, ta = organize_data(data_train.iloc[:10, 0], F=2, T=2)\n>>> xa.shape == (7, 2) and ya.shape == (7,) and (ta.shape == (7,))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> xa, ya, ta = organize_data(data_train.iloc[:10, 0], F=2, T=2)\n>>> bool(np.isclose(xa.mean(), 8159.785714285715, atol=0.001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> xa, ya, ta = organize_data(data_train.iloc[:10, 0], F=2, T=2)\n>>> bool(np.isclose(ya[0], 7917, atol=0.001)) and bool(np.isclose(ya[-1], 9381, atol=0.001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pandas import Timestamp\n>>> xa, ya, ta = organize_data(data_train.iloc[:10, 0], F=2, T=2)\n>>> ta[0] == Timestamp('2004-05-01 03:00:00') and ta[-1] == Timestamp('2004-05-01 09:00:00')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> T == 6 and F == 12\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> from pandas import Timestamp\n>>> isinstance(ttrain[0], Timestamp) and isinstance(tvalid[0], Timestamp) and isinstance(ttest[0], Timestamp)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.all(np.isclose(Xtrain[0, :], [-1.0773, -1.3391, -1.5005, -1.6114, -1.6486, -1.6577], atol=0.01)))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.all(np.isclose(Xtrain[-1, :], [0.145, 0.1817, 0.1629, 0.1154, 0.0891, 0.0428], atol=0.01)))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.all(np.isclose(ytrain[[0, -1]], [-1.0143, -0.7011], atol=0.01)))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> Xtrain.shape == (40898, 6) and ytrain.shape == (40898,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> from pandas import Timestamp\n>>> ttrain[0] == Timestamp('2004-05-01 07:00:00')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(Xtrain, 4) == '3013f8ed8a3acc56c34394da4b4f56bb' and get_hash(ytrain, 4) == '9595bff50cf6cdbc82efe15a3caeb857'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(Xvalid, 4) == 'd8fbf1bc6c5284c7b2d3153c56bc969b' and get_hash(yvalid, 4) == '94beaf31ceb6f129e8fdfcd2b05ea157'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(Xtest, 4) == 'e8e6916ed45e6bd290710d6273f5181f' and get_hash(ytest, 4) == 'be4b23b8a6d4983b948e4a7a091d0a88'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(linreg, LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> hasattr(linreg, 'coef_') and hasattr(linreg, 'intercept_')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(linreg.coef_, 4) == '6688577e040683c9e60f0bc61aaa4f7f'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(linreg.intercept_, 4) == '15857fea29fe449b2dad03e61cfee3a8'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(assess([1, 2, 3], [5, 5, 6], [7, 8, 9]), 0.2, atol=0.001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(np.isclose(assess(Xvalid[:, -1], yvalid, linreg.predict(Xvalid)), 0.310725112468464, atol=0.001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(np.isclose(assess(Xtest[:, -1], ytest, linreg.predict(Xtest)), 0.3274380065847301, atol=0.001))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pandas import Timestamp\n>>> bool(np.all(append_hour_of_day(np.ones((3, 2)), [Timestamp('07:00:00'), Timestamp('08:00:00'), Timestamp('09:00:00')]) == np.array([[1.0, 1.0, 7.0], [1.0, 1.0, 8.0], [1.0, 1.0, 9.0]])))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> Xtrain_hour = append_hour_of_day(Xtrain, ttrain)\n>>> Xvalid_hour = append_hour_of_day(Xvalid, tvalid)\n>>> Xtest_hour = append_hour_of_day(Xtest, ttest)\n>>> Xtrain_hour.shape == (40898, 7) and Xvalid_hour.shape == (5828, 7) and (Xtest_hour.shape == (11673, 7))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> get_hash(Xtrain_hour, 4) == 'db7ee82f4e09350ecb2cac63a11f9147'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(Xvalid_hour, 4) == 'fcd6674b42769e0a6230388d8fd8a2f6'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(Xtest_hour, 4) == '1ecb2a4390e4f39242b7603dc6c7849d'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
